{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7.078657420964836, -25.02194729819945, -6.325...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7.1665441896812405, -25.24814281113481, -1.60...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7.184905955583264, -28.73273351008029, -3.906...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7.034989672359181, -28.195340884727596, -3.54...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7.003780771426295, -28.139888943590634, -0.70...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features labels\n",
       "0  [7.078657420964836, -25.02194729819945, -6.325...    sil\n",
       "1  [7.1665441896812405, -25.24814281113481, -1.60...    sil\n",
       "2  [7.184905955583264, -28.73273351008029, -3.906...    sil\n",
       "3  [7.034989672359181, -28.195340884727596, -3.54...    sil\n",
       "4  [7.003780771426295, -28.139888943590634, -0.70...    sil"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "\n",
    "timit_df = pd.read_hdf(\"./train_features/mfcc/timit.hdf\")\n",
    "timit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sil', 'sh', 'ih', 'hh', 'eh', 'jh', 'd', 'ah', 'k', 's', 'uw', '', 'n', 'g', 'r', 'w', 'aa', 'dx', 'er', 'l', 'y', 'uh', 'ae', 'm', 'oy', 'dh', 'iy', 'v', 'f', 't', 'ow', 'ch', 'b', 'ng', 'ay', 'th', 'ey', 'p', 'aw', 'z']\n"
     ]
    }
   ],
   "source": [
    "phone_names = timit_df['labels'].unique().tolist()#find unique values\n",
    "print(phone_names)\n",
    "phoneme_wise_list = []\n",
    "#file = open('phoneme_name.txt', 'a+')\n",
    "for i in range (len(phone_names)):\n",
    "    phoneme_wise_list.append(timit_df[timit_df['labels']==phone_names[i]]) # seperating data phoneme wise\n",
    "    #file.write(names[i]+\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GMM a) for MFCC (13), b) MFCC + Delta MFCC (26), c) MFCC + Delta + Delta-Delta and all the (a), (b), (c) i) with and ii) without energy coefficient (zeroeth coefficient and corresponding 14th coeff, and 27th coeff) - all for one size of GMM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_df1 = pd.read_hdf(\"./train_features/mfcc_delta/timit.hdf\")\n",
    "timit_df2 = pd.read_hdf(\"./train_features/mfcc_delta_delta/timit.hdf\")\n",
    "\n",
    "phoneme_wise_list1 = []\n",
    "phoneme_wise_list2 = []\n",
    "for i in range (len(phone_names)):\n",
    "    phoneme_wise_list1.append(timit_df1[timit_df1['labels']==phone_names[i]])\n",
    "\n",
    "for i in range (len(phone_names)):\n",
    "    phoneme_wise_list2.append(timit_df2[timit_df2['labels']==phone_names[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) with i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    models.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_withEC//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) with i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list1)):\n",
    "    features = np.array(phoneme_wise_list1[i][\"features\"].tolist())\n",
    "    models.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_delta_withEC//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) with i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list2)):\n",
    "    features = np.array(phoneme_wise_list2[i][\"features\"].tolist())\n",
    "    models.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_delta_delta_withEC//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) with ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) with ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list1)):\n",
    "    features = np.array(phoneme_wise_list1[i][\"features\"].tolist())\n",
    "    temp1 = features[:,1:12]\n",
    "    temp2 = features[:,14:25]\n",
    "    features = np.hstack((temp1, temp2))\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    models.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_delta//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) with ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list2)):\n",
    "    features = np.array(phoneme_wise_list2[i][\"features\"].tolist())\n",
    "    temp1 = features[:,1:12]\n",
    "    temp2 = features[:,14:25]\n",
    "    temp3 = features[:,27:38]\n",
    "    features = np.hstack((temp1, temp2, temp3))\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    models.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_delta_delta//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GMM with different number of mixtures only for Case (a) for MFCC (ii) without energy coefficients - (2, 4, 8, 16, 32, 64,128,256). For 2 already did above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21274401, 0.1796321 , 0.29638121, 0.31124268])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=4,covariance_type='diag').fit(features))\n",
    "    path = \"models//004//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14738474, 0.18062229, 0.10776701, 0.06766057, 0.23309269,\n",
       "       0.04354412, 0.12702131, 0.09290727])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models =[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=8,covariance_type='diag').fit(features))\n",
    "    path = \"models//008//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component : 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05148623, 0.08425272, 0.04899861, 0.05866363, 0.03874476,\n",
       "       0.03612453, 0.06370626, 0.1464804 , 0.0536198 , 0.08888698,\n",
       "       0.09526805, 0.03355841, 0.06354869, 0.06192713, 0.02635753,\n",
       "       0.04837629])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models =[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=16,covariance_type='diag').fit(features))\n",
    "    path = \"models//016//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component : 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04470096, 0.03862213, 0.04934954, 0.03353482, 0.01474038,\n",
       "       0.03384174, 0.01544035, 0.03461123, 0.02586804, 0.01924646,\n",
       "       0.02988094, 0.04262006, 0.01519346, 0.0466366 , 0.02351846,\n",
       "       0.02957312, 0.01296083, 0.02698082, 0.0150077 , 0.03344873,\n",
       "       0.02858623, 0.00681384, 0.02575541, 0.02739157, 0.0327493 ,\n",
       "       0.07406895, 0.02053717, 0.04766103, 0.02632993, 0.0468092 ,\n",
       "       0.0276443 , 0.04987671])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models =[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=32,covariance_type='diag').fit(features))\n",
    "    path = \"models//032//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component :  64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02077035, 0.03454446, 0.02923573, 0.0226325 , 0.00935513,\n",
       "       0.00600882, 0.01880534, 0.03948364, 0.01423543, 0.03022642,\n",
       "       0.01750583, 0.00664414, 0.01288382, 0.02448705, 0.0067563 ,\n",
       "       0.01427434, 0.02271633, 0.00755569, 0.01270767, 0.01433372,\n",
       "       0.01782577, 0.00361262, 0.01256615, 0.01262096, 0.02201846,\n",
       "       0.01018496, 0.02064451, 0.01617888, 0.02060659, 0.02204358,\n",
       "       0.01703198, 0.01649919, 0.01710358, 0.00753165, 0.00734402,\n",
       "       0.01928949, 0.01071695, 0.00498488, 0.01136363, 0.00673497,\n",
       "       0.01960876, 0.00895923, 0.00471328, 0.02149252, 0.00367673,\n",
       "       0.02302356, 0.01667931, 0.01156769, 0.01357161, 0.02945956,\n",
       "       0.00721997, 0.01290925, 0.01436295, 0.01494679, 0.01113387,\n",
       "       0.01022191, 0.00357005, 0.01816778, 0.01574963, 0.00761695,\n",
       "       0.01548601, 0.01747773, 0.01661054, 0.03970879])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models =[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=64,covariance_type='diag').fit(features))\n",
    "    path = \"models//064//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component : 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0084934 , 0.00920839, 0.00879792, 0.01095725, 0.01002664,\n",
       "       0.00463478, 0.00736503, 0.00205217, 0.00950587, 0.00644958,\n",
       "       0.00323567, 0.00346256, 0.00610388, 0.01244467, 0.00391935,\n",
       "       0.01204577, 0.01352495, 0.00808966, 0.01442885, 0.0033721 ,\n",
       "       0.0252694 , 0.0078184 , 0.00311834, 0.00344258, 0.01119713,\n",
       "       0.00250822, 0.00389911, 0.00330809, 0.00676563, 0.00357434,\n",
       "       0.00732526, 0.00912822, 0.00811034, 0.00534894, 0.01001274,\n",
       "       0.01728464, 0.00450137, 0.00331219, 0.01550178, 0.00353652,\n",
       "       0.00595993, 0.00909362, 0.00717442, 0.00877928, 0.01313889,\n",
       "       0.00573973, 0.0028576 , 0.00566799, 0.00967581, 0.0184491 ,\n",
       "       0.01389938, 0.01355892, 0.00543721, 0.00581901, 0.00568286,\n",
       "       0.01221258, 0.00771289, 0.00285645, 0.01101131, 0.01090031,\n",
       "       0.00394112, 0.01527209, 0.00343885, 0.00465828, 0.0071383 ,\n",
       "       0.00856357, 0.0048288 , 0.00523171, 0.006911  , 0.01106092,\n",
       "       0.00862113, 0.00146754, 0.00656401, 0.00281414, 0.0082477 ,\n",
       "       0.00256135, 0.00800561, 0.00275495, 0.01287955, 0.00645119,\n",
       "       0.00278218, 0.01861904, 0.00632027, 0.00963866, 0.00449806,\n",
       "       0.00323546, 0.01063938, 0.0226372 , 0.00789177, 0.00339504,\n",
       "       0.00879655, 0.01053945, 0.00888376, 0.00921678, 0.0033772 ,\n",
       "       0.0077754 , 0.00592461, 0.00989592, 0.00887159, 0.00757079,\n",
       "       0.0148682 , 0.00573094, 0.00649893, 0.00548809, 0.00545174,\n",
       "       0.01622715, 0.00351849, 0.00859496, 0.00750289, 0.01208654,\n",
       "       0.00891225, 0.00848999, 0.00303407, 0.0048381 , 0.01255253,\n",
       "       0.0034473 , 0.00664017, 0.01119865, 0.01438485, 0.00253486,\n",
       "       0.00430623, 0.00245921, 0.00971338, 0.00700878, 0.00928969,\n",
       "       0.00533353, 0.00610225, 0.00315629])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models =[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=128,covariance_type='diag').fit(features))\n",
    "    path = \"models//128//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixture component : 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00278751, 0.01171373, 0.00772138, 0.00946035, 0.00452782,\n",
       "       0.01343315, 0.00109623, 0.00454664, 0.00567267, 0.00249324,\n",
       "       0.0047108 , 0.00245254, 0.00222697, 0.00182964, 0.00409505,\n",
       "       0.00625018, 0.00537388, 0.00435088, 0.00211449, 0.0067587 ,\n",
       "       0.00430521, 0.00477272, 0.00198557, 0.00145955, 0.00269664,\n",
       "       0.00262734, 0.0030558 , 0.00157375, 0.00180489, 0.00438453,\n",
       "       0.00295047, 0.00614255, 0.0072621 , 0.00775981, 0.00637283,\n",
       "       0.0039111 , 0.00404864, 0.0015058 , 0.0029019 , 0.00424184,\n",
       "       0.01388828, 0.00463615, 0.00106698, 0.00394301, 0.00264216,\n",
       "       0.00545745, 0.00367864, 0.0027781 , 0.00220251, 0.00343419,\n",
       "       0.00408903, 0.00121668, 0.00338096, 0.0040665 , 0.00457781,\n",
       "       0.0026857 , 0.00303785, 0.00481003, 0.00327816, 0.0030829 ,\n",
       "       0.00366169, 0.00401562, 0.00124203, 0.00360524, 0.00686929,\n",
       "       0.00130374, 0.00645326, 0.00451039, 0.00572758, 0.00480041,\n",
       "       0.00603144, 0.0045752 , 0.00523089, 0.00745803, 0.00229207,\n",
       "       0.00475993, 0.00389833, 0.00344663, 0.00106545, 0.00480766,\n",
       "       0.00318532, 0.00428257, 0.01264933, 0.00315506, 0.00170601,\n",
       "       0.01267312, 0.00361966, 0.0027567 , 0.0031956 , 0.00588725,\n",
       "       0.00794367, 0.00285942, 0.00242086, 0.00130354, 0.00386037,\n",
       "       0.00321738, 0.00642209, 0.00109968, 0.00178604, 0.00374317,\n",
       "       0.00572693, 0.00427283, 0.00182339, 0.00087491, 0.00322219,\n",
       "       0.00285088, 0.00558414, 0.00103208, 0.0015866 , 0.00904633,\n",
       "       0.00334188, 0.00250066, 0.00545701, 0.00155181, 0.00602681,\n",
       "       0.00506496, 0.00152124, 0.00518196, 0.00320452, 0.00561224,\n",
       "       0.00147613, 0.00129144, 0.00297564, 0.00134511, 0.00561148,\n",
       "       0.00294944, 0.00104012, 0.00254869, 0.00374137, 0.00372876,\n",
       "       0.00612251, 0.00226033, 0.00183788, 0.00230855, 0.00487678,\n",
       "       0.00312781, 0.00271671, 0.00508189, 0.0021545 , 0.0049788 ,\n",
       "       0.00348294, 0.00121948, 0.00445786, 0.00557948, 0.00154188,\n",
       "       0.00807529, 0.00149959, 0.00490772, 0.00081716, 0.00362085,\n",
       "       0.00389109, 0.00358567, 0.00880686, 0.00348279, 0.00155381,\n",
       "       0.0040607 , 0.00506138, 0.00072269, 0.00348482, 0.00454804,\n",
       "       0.00428099, 0.00194571, 0.00236949, 0.0024918 , 0.00201701,\n",
       "       0.00637203, 0.00154577, 0.00483231, 0.00266145, 0.00260379,\n",
       "       0.0015638 , 0.00587919, 0.00472357, 0.00210681, 0.00415785,\n",
       "       0.00513507, 0.00177589, 0.00471682, 0.00135892, 0.00167511,\n",
       "       0.00173304, 0.00150934, 0.00353231, 0.00297943, 0.00370869,\n",
       "       0.00421605, 0.00254197, 0.0040521 , 0.00999177, 0.00231065,\n",
       "       0.00233612, 0.00302573, 0.00221472, 0.00116338, 0.0014178 ,\n",
       "       0.00671083, 0.00436477, 0.0030105 , 0.00336568, 0.00124633,\n",
       "       0.00103583, 0.00282798, 0.0016001 , 0.00609997, 0.00151865,\n",
       "       0.00502733, 0.00527457, 0.00126946, 0.00519636, 0.00218943,\n",
       "       0.00582004, 0.00376276, 0.00353053, 0.00513829, 0.0089645 ,\n",
       "       0.00659205, 0.00225422, 0.00079886, 0.00554867, 0.0021249 ,\n",
       "       0.00420329, 0.00450055, 0.00179356, 0.00149942, 0.00390903,\n",
       "       0.00184893, 0.00310144, 0.00545361, 0.00282108, 0.00465135,\n",
       "       0.00409998, 0.002063  , 0.00633008, 0.00177298, 0.00442751,\n",
       "       0.00369817, 0.01415668, 0.00091418, 0.00441659, 0.00386984,\n",
       "       0.00524566, 0.00256053, 0.00540566, 0.00273936, 0.00131715,\n",
       "       0.00681676, 0.0047207 , 0.00120627, 0.00238061, 0.00474003,\n",
       "       0.00582139, 0.00609247, 0.00348516, 0.0017308 , 0.01158372,\n",
       "       0.0054923 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonemes\n",
    "models =[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    models.append(GMM(n_components=256,covariance_type='diag').fit(features))\n",
    "    path = \"models//256//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(models[i] , open(path, 'wb'))\n",
    "models[0].weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
