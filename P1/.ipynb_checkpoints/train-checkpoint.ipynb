{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7.078657420964836, -25.02194729819945, -6.325...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7.1665441896812405, -25.24814281113481, -1.60...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7.184905955583264, -28.73273351008029, -3.906...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7.034989672359181, -28.195340884727596, -3.54...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7.003780771426295, -28.139888943590634, -0.70...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features labels\n",
       "0  [7.078657420964836, -25.02194729819945, -6.325...    sil\n",
       "1  [7.1665441896812405, -25.24814281113481, -1.60...    sil\n",
       "2  [7.184905955583264, -28.73273351008029, -3.906...    sil\n",
       "3  [7.034989672359181, -28.195340884727596, -3.54...    sil\n",
       "4  [7.003780771426295, -28.139888943590634, -0.70...    sil"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "\n",
    "timit_df = pd.read_hdf(\"./train_features/mfcc/timit.hdf\")\n",
    "timit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sil', 'sh', 'ih', 'hh', 'eh', 'jh', 'd', 'ah', 'k', 's', 'uw', '', 'n', 'g', 'r', 'w', 'aa', 'dx', 'er', 'l', 'y', 'uh', 'ae', 'm', 'oy', 'dh', 'iy', 'v', 'f', 't', 'ow', 'ch', 'b', 'ng', 'ay', 'th', 'ey', 'p', 'aw', 'z']\n"
     ]
    }
   ],
   "source": [
    "phone_names = timit_df['labels'].unique().tolist()#find unique values\n",
    "print(phone_names)\n",
    "phoneme_wise_list = []\n",
    "#file = open('phoneme_name.txt', 'a+')\n",
    "for i in range (len(phone_names)):\n",
    "    phoneme_wise_list.append(timit_df[timit_df['labels']==phone_names[i]]) # seperating data phoneme wise\n",
    "    #file.write(names[i]+\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GMM a) for MFCC (13), b) MFCC + Delta MFCC (26), c) MFCC + Delta + Delta-Delta and all the (a), (b), (c) i) with and ii) without energy coefficient (zeroeth coefficient and corresponding 14th coeff, and 27th coeff) - all for one size of GMM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_df1 = pd.read_hdf(\"./train_features/mfcc_delta/timit.hdf\")\n",
    "timit_df2 = pd.read_hdf(\"./train_features/mfcc_delta_delta/timit.hdf\")\n",
    "\n",
    "phoneme_wise_list1 = []\n",
    "phoneme_wise_list2 = []\n",
    "for i in range (len(phone_names)):\n",
    "    phoneme_wise_list1.append(timit_df1[timit_df1['labels']==phone_names[i]])\n",
    "\n",
    "for i in range (len(phone_names)):\n",
    "    phoneme_wise_list2.append(timit_df2[timit_df2['labels']==phone_names[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) with i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ea7d4168bce3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoneme_wise_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoneme_wise_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcovariance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'diag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"models//002_mfcc_withEC//\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mphone_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list)):\n",
    "    features = np.array(phoneme_wise_list[i][\"features\"].tolist())\n",
    "    gmm.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_withEC//\"+phone_names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) with i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "GMM=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list1)):\n",
    "    features = np.array(phoneme_wise_list1[i][\"features\"].tolist())\n",
    "    GMM.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_delta_withEC//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(GMM[i] , open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) with i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "GMM=[]\n",
    "\n",
    "for i in range (len(phoneme_wise_list2)):\n",
    "    features = np.array(phoneme_wise_list2[i][\"features\"].tolist())\n",
    "    GMM.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc_delta_delta_withEC//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(GMM[i] , open(path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    features = features[:,1:]\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=2,covariance_type='diag').fit(features))\n",
    "    path = \"models//002_mfcc//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=4,covariance_type='diag').fit(features))\n",
    "    path = \"models//004//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07521546, 0.06975178, 0.11976575, 0.16719654, 0.23605798,\n",
       "       0.04946315, 0.11452664, 0.16802271])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=8,covariance_type='diag').fit(features))\n",
    "    path = \"models//008//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "gmm[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08497634, 0.05882654, 0.07760709, 0.04470488, 0.04641883,\n",
       "       0.03680472, 0.04971103, 0.1607023 , 0.01890042, 0.07527197,\n",
       "       0.0567751 , 0.04666728, 0.13797005, 0.02790237, 0.05270471,\n",
       "       0.02405637])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=16,covariance_type='diag').fit(features))\n",
    "    path = \"models//016//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "gmm[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01678299, 0.03958762, 0.02882221, 0.01599941, 0.07282294,\n",
       "       0.02897067, 0.0394837 , 0.04073423, 0.0798323 , 0.03158047,\n",
       "       0.01344217, 0.02491827, 0.07089552, 0.01473945, 0.05898002,\n",
       "       0.05883295, 0.03535959, 0.03174456, 0.03449507, 0.02487592,\n",
       "       0.01282576, 0.0156964 , 0.00702428, 0.04514724, 0.01247972,\n",
       "       0.01775899, 0.01971834, 0.02940523, 0.00786241, 0.0245037 ,\n",
       "       0.02873217, 0.01594569])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=32,covariance_type='diag').fit(features))\n",
    "    path = \"models//032//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "gmm[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01439826, 0.01673311, 0.01548026, 0.00710054, 0.02101234,\n",
       "       0.00607077, 0.02223825, 0.01617648, 0.00672839, 0.01246927,\n",
       "       0.01119594, 0.00544702, 0.01257111, 0.0261212 , 0.01765139,\n",
       "       0.01271065, 0.00847311, 0.0111372 , 0.02799351, 0.00919739,\n",
       "       0.01690369, 0.00852435, 0.01036348, 0.02214473, 0.01859076,\n",
       "       0.02387903, 0.00664524, 0.00679999, 0.00978623, 0.02706384,\n",
       "       0.01447659, 0.01318505, 0.01425207, 0.0165274 , 0.02149278,\n",
       "       0.01736819, 0.01476271, 0.02237873, 0.00964148, 0.00386759,\n",
       "       0.01823014, 0.02138983, 0.01551616, 0.0060238 , 0.00607371,\n",
       "       0.01020146, 0.0210911 , 0.05345411, 0.01198556, 0.01858713,\n",
       "       0.01617191, 0.01356419, 0.01718073, 0.00941559, 0.01353813,\n",
       "       0.04040509, 0.0141441 , 0.01648468, 0.00845885, 0.04294218,\n",
       "       0.01097957, 0.0197395 , 0.00589353, 0.00896886])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=64,covariance_type='diag').fit(features))\n",
    "    path = \"models//064//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "gmm[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00268187, 0.02109148, 0.0102035 , 0.00329531, 0.00810982,\n",
       "       0.00481884, 0.00309956, 0.00638775, 0.00592221, 0.00360183,\n",
       "       0.01070057, 0.00708124, 0.00744472, 0.01568937, 0.00378299,\n",
       "       0.00511919, 0.00465003, 0.00277244, 0.00517922, 0.00856524,\n",
       "       0.00895579, 0.00779569, 0.00343432, 0.00782413, 0.01350756,\n",
       "       0.00807449, 0.00909022, 0.01026175, 0.00956003, 0.01164903,\n",
       "       0.00498303, 0.00813998, 0.01024138, 0.00479031, 0.02736318,\n",
       "       0.00462437, 0.00245548, 0.00217359, 0.00666288, 0.00743877,\n",
       "       0.01195176, 0.00538581, 0.00469908, 0.00787081, 0.01115173,\n",
       "       0.0088095 , 0.00733307, 0.00247794, 0.0058632 , 0.0116618 ,\n",
       "       0.0113591 , 0.00561139, 0.00514772, 0.01878819, 0.00972123,\n",
       "       0.00968178, 0.00874562, 0.01211726, 0.00368247, 0.00368882,\n",
       "       0.00505525, 0.00262902, 0.01027472, 0.00690503, 0.01474958,\n",
       "       0.00272035, 0.00426474, 0.01326162, 0.01088744, 0.00671958,\n",
       "       0.00287216, 0.00543669, 0.00959202, 0.00493225, 0.00693226,\n",
       "       0.00737799, 0.0041391 , 0.0097589 , 0.01458763, 0.00167588,\n",
       "       0.00458334, 0.00308988, 0.00587466, 0.00908366, 0.00217368,\n",
       "       0.00397721, 0.00363531, 0.00483417, 0.00430396, 0.00599023,\n",
       "       0.01272808, 0.02687624, 0.00413108, 0.00623883, 0.0089288 ,\n",
       "       0.01160653, 0.00577859, 0.00647053, 0.00251292, 0.00363675,\n",
       "       0.0036688 , 0.00821687, 0.00160058, 0.00835669, 0.02008006,\n",
       "       0.00472287, 0.00575356, 0.00267214, 0.00482812, 0.0074017 ,\n",
       "       0.02241612, 0.00434082, 0.00863985, 0.00603803, 0.00777955,\n",
       "       0.00658627, 0.00661938, 0.00967987, 0.01860464, 0.00782219,\n",
       "       0.02211092, 0.00278185, 0.00330325, 0.02574342, 0.00799514,\n",
       "       0.00628554, 0.0051462 , 0.00460737])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=128,covariance_type='diag').fit(features))\n",
    "    path = \"models//128//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "gmm[0].weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM with mixture component 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00577339, 0.00324434, 0.00927373, 0.00754755, 0.00491971,\n",
       "       0.00397021, 0.0044733 , 0.00422358, 0.00344773, 0.00715857,\n",
       "       0.00291641, 0.00319123, 0.00209784, 0.00261551, 0.0143747 ,\n",
       "       0.00342285, 0.00734643, 0.00268487, 0.00166293, 0.00386216,\n",
       "       0.00374874, 0.00226592, 0.0068496 , 0.00341732, 0.00475671,\n",
       "       0.00403699, 0.00280862, 0.00302388, 0.0052855 , 0.01574067,\n",
       "       0.00793925, 0.00097071, 0.00448317, 0.00423543, 0.01118172,\n",
       "       0.00130383, 0.00676788, 0.00499786, 0.00588106, 0.00407722,\n",
       "       0.00241124, 0.00293744, 0.00115779, 0.00492323, 0.00593642,\n",
       "       0.00614742, 0.00280575, 0.00380812, 0.00299192, 0.00497548,\n",
       "       0.00338736, 0.00474654, 0.00256743, 0.00132154, 0.0032618 ,\n",
       "       0.00098177, 0.00265073, 0.00328706, 0.00349321, 0.00356319,\n",
       "       0.0022941 , 0.00543994, 0.00163408, 0.00127126, 0.00210081,\n",
       "       0.00603363, 0.00245143, 0.00379577, 0.00569554, 0.00581092,\n",
       "       0.00233543, 0.00278428, 0.0053854 , 0.00472927, 0.00363308,\n",
       "       0.00862324, 0.00149292, 0.0018359 , 0.00261572, 0.00192792,\n",
       "       0.00388762, 0.00287773, 0.00144098, 0.001684  , 0.00433314,\n",
       "       0.00511402, 0.00308225, 0.0016169 , 0.00306915, 0.00559771,\n",
       "       0.00200294, 0.00239892, 0.00197631, 0.00565089, 0.00387332,\n",
       "       0.00116067, 0.00160762, 0.00220971, 0.00261494, 0.00292169,\n",
       "       0.00188035, 0.00726595, 0.00141243, 0.00368603, 0.00280763,\n",
       "       0.00290057, 0.0017034 , 0.00243273, 0.00598212, 0.00225238,\n",
       "       0.00404311, 0.00357583, 0.00516569, 0.0035276 , 0.00179877,\n",
       "       0.00129916, 0.004312  , 0.00432773, 0.00548462, 0.00574983,\n",
       "       0.00366802, 0.00243278, 0.0027693 , 0.0048986 , 0.00623478,\n",
       "       0.00165326, 0.00426572, 0.00413395, 0.00140562, 0.00304309,\n",
       "       0.00216854, 0.00504429, 0.00360431, 0.00121019, 0.00394488,\n",
       "       0.00079632, 0.00227335, 0.002969  , 0.00423256, 0.00493364,\n",
       "       0.00279946, 0.00465167, 0.01076961, 0.00463717, 0.00335457,\n",
       "       0.00134805, 0.00584735, 0.00150037, 0.00410212, 0.0010268 ,\n",
       "       0.00404658, 0.00396206, 0.0065354 , 0.00437545, 0.00625974,\n",
       "       0.00131663, 0.00265571, 0.00450272, 0.00399581, 0.01037058,\n",
       "       0.00512266, 0.00253539, 0.00085173, 0.00172208, 0.00300554,\n",
       "       0.00471636, 0.00093618, 0.00547645, 0.00212669, 0.00148071,\n",
       "       0.00295483, 0.00222653, 0.00959446, 0.00230832, 0.00510322,\n",
       "       0.00277506, 0.00081941, 0.00392636, 0.0064398 , 0.00231399,\n",
       "       0.00376557, 0.0036226 , 0.0023498 , 0.00058857, 0.00136307,\n",
       "       0.00472936, 0.00619754, 0.00063857, 0.00180309, 0.00215107,\n",
       "       0.00527352, 0.00421372, 0.00333537, 0.00409007, 0.00266187,\n",
       "       0.00241095, 0.01552611, 0.00197261, 0.0052224 , 0.00397438,\n",
       "       0.00119741, 0.00236171, 0.00439075, 0.00243354, 0.00699771,\n",
       "       0.00187552, 0.00372337, 0.00378153, 0.00179622, 0.00921664,\n",
       "       0.00565918, 0.00335603, 0.0041659 , 0.00225369, 0.00277813,\n",
       "       0.00497231, 0.00355068, 0.00209833, 0.0072425 , 0.00507239,\n",
       "       0.00993485, 0.00161779, 0.01592534, 0.00300777, 0.01265235,\n",
       "       0.00192054, 0.00179932, 0.0018651 , 0.00293463, 0.00234795,\n",
       "       0.00348217, 0.00873072, 0.00211397, 0.00257373, 0.00330893,\n",
       "       0.0016399 , 0.00062896, 0.00208551, 0.00316194, 0.00470816,\n",
       "       0.0105495 , 0.00086473, 0.00375796, 0.00209687, 0.01507068,\n",
       "       0.0025013 , 0.00658395, 0.00076333, 0.00126404, 0.0018852 ,\n",
       "       0.00376059, 0.00636597, 0.00262416, 0.00294669, 0.0041555 ,\n",
       "       0.00142675])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating 40 diffrent gmm for different phonyms\n",
    "gmm=[]\n",
    "\n",
    "for i in range (len(store)):\n",
    "    features = np.array(store[i][\"features\"].tolist())\n",
    "    #label = np.array(store[i][\"labels\"].unique().tolist())\n",
    "    gmm.append(GMM(n_components=256,covariance_type='diag').fit(features))\n",
    "    path = \"models//256//\"+names[i]+\".pkl\"\n",
    "    pickle.dump(gmm[i] , open(path, 'wb'))\n",
    "gmm[0].weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
